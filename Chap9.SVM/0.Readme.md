## サポートベクターマシンのサンプルプログラム

Chapter 9.5, Chapter 9.8で説明したSVMの逐次解法を実装しました．
具体的な漸化式は本文中に(Program)と書いてあります．

実行すると，逐次的に識別境界面が決まり，パターンの点の大きさが変化します．
パターンが大きな点で表示されているものがサポートベクトルです．
学習の過程では，サポートベクトルの数や，どのパターンがサポートベクトルになるのかが
変化し，最終的にサポートベクトルが決まっていく様子が確認できます．

このプログラムはハードマージンとソフトマージンの両方に対応しています．

データはランダムに生成します．

    -# 生成する個数は "-n TRAIN_NUM" で指定します． defaultでは各クラス10データで計20個です．
    -# 2クラス間のオーバーラップ量を "-o OVERWRAP" で指定できます．defaultでは0.0になっています．
        例えば オーバラップ量が0.0なら2クラスのデータは重ならず線形分離できます．hard-margin用ですね．
        オーバーラップ量が1.0だと100%重なります．
        soft-marginの実験用にデータを作成するときには10%から30%程度を指定すると良いかもしれません．
    -# 乱数の種を指定すると同じデータを生成できます．できるだけ指定したほうが良いでしょう．
        "-s SEED"で指定できます．自然数を指定します．

学習について
    -# 最急降下法を何回回すかは"-i ITER_NUM"で指定できます．defaultでは 10000回になっています．
    -# 学習率は "-e ETA"で指定できます．defaultでは0.1になっていますが，これ以上大きくすると発散するかもしれません．
    -# soft-marginで学習するなら "-C SOFTC"を指定します．defaultでは1.e10と大きな値になっていて，ハートマージンSVMとして動作します．
        これをC=0.5とかにするとソフトマージンSVMとして動作します．本書に詳しい解説があります．


```
usage: SVM.py [-h] [-n TRAIN_NUM] [-o OVERWRAP] [-i ITER_NUM] [-s SEED]
              [-e ETA] [-C SOFTC]

optional arguments:
  -h, --help            show this help message and exit
  -n TRAIN_NUM, --train_num TRAIN_NUM
                        number of training data (default=20)
  -o OVERWRAP, --overwrap OVERWRAP
                        overwrap rate of 2 class data (default=0.0[no
                        overwrap])
  -i ITER_NUM, --iter_num ITER_NUM
                        itteration number for training (default=10000)
  -s SEED, --seed SEED  random seed number (default:Random)
  -e ETA, --eta ETA     eta (default=0.1)
  -C SOFTC, --softC SOFTC
                        soft margin C (typically, C=0.5) (default C=1.e10
                        means Hard Margin)
```

とりあえず，

``
    ./SVM.py -s 1
``

と乱数の種だけを指定して動かしてみると，
サポートベクトルが変化していくのが表示されます．
グラフ上のデータ点が小さく表示されるとサポートベクトルではなくなります．
それは端末上に表示されるαの値が0になっていることからも分かります．
最初のうちはαは値を持っていますが，どんどん0になっていきサポートベクトルが限定されていく様子が見れるでしょう．
このようにSVMは学習されるのです．
